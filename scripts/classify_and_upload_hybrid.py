#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
í•˜ì´ë¸Œë¦¬ë“œ ë¶„ë¥˜ (í‚¤ì›Œë“œ + AI) í›„ Notion ì—…ë¡œë“œ (í´ëŸ¬ìŠ¤í„°ë§ í¬í•¨)

- í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (ë¹ ë¦„, ë¬´ë£Œ)
- AI ê¸°ë°˜ ë¶„ë¥˜ (ì •í™•í•¨, ë¹„ìš© ë°œìƒ)
- ë‘ ê²°ê³¼ë¥¼ ë³‘í•©í•˜ì—¬ ìµœì ì˜ ë¶„ë¥˜ ìˆ˜í–‰
"""
import sys
import os
import json
import requests
from pathlib import Path
from datetime import datetime, date

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root / "aide-data-core"))
sys.path.insert(0, str(project_root / "scripts"))

from dotenv import load_dotenv
load_dotenv()

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from aide_data_core.models import NaverNews

# í´ëŸ¬ìŠ¤í„°ë§ ì„œë¹„ìŠ¤ import
from clustering_service import apply_clustering_to_articles

# AI ë¶„ë¥˜ ì„œë¹„ìŠ¤ import
from ai_classifier import AIClassifier

# AI ë¶„ë¥˜ í™œì„±í™” ì—¬ë¶€ (í™˜ê²½ë³€ìˆ˜ë¡œ ì œì–´ ê°€ëŠ¥)
USE_AI_CLASSIFICATION = os.getenv("USE_AI_CLASSIFICATION", "true").lower() == "true"
AI_CONFIDENCE_THRESHOLD = int(os.getenv("AI_CONFIDENCE_THRESHOLD", "70"))  # 70% ì´ìƒ ì‹ ë¢°ë„ë§Œ ì‚¬ìš©

# Notion ì„¤ì •
NOTION_API_KEY = os.getenv("NOTION_API_KEY")
NOTION_API_VERSION = "2022-06-28"

# ì¹´í…Œê³ ë¦¬ í˜ì´ì§€ ë§¤í•‘ (insight_testì—ì„œ)
CATEGORY_PAGES = {
    "policy_regulation": "28c18b63af4d80d9ba62c35619d4ad10",
    "market_transaction": "28c18b63af4d809e8021c3e407f622ee",
    "development_supply": "28c18b63af4d80f78093fe7512abae46",
    "finance_investment": "28c18b63af4d8013bbd0d6cd187f37a1",
    "construction_development": "28c18b63af4d80118c2ae66a33376c7b",
    "construction": "28c18b63af4d80749894d35875e59542",
    "commercial_realestate": "28c18b63af4d805ea7b1da7fa10a0e87",
    "auction_public_sale": "28c18b63af4d80baa436e66c7464845e",
}

CATEGORY_NAMES = {
    "policy_regulation": "ì •ì±…Â·ê·œì œ",
    "market_transaction": "ì‹œì¥ë™í–¥",
    "development_supply": "ë¶„ì–‘Â·ì…ì£¼",
    "finance_investment": "ê¸ˆìœµÂ·íˆ¬ì",
    "construction_development": "ê°œë°œÂ·ì‚¬ì—…",
    "construction": "ê±´ì„¤Â·ì‹œê³µ",
    "commercial_realestate": "ìƒì—…ìš© ë¶€ë™ì‚°",
    "auction_public_sale": "ê²½ë§¤Â·ê³µë§¤",
}

# í‚¤ì›Œë“œ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ (í™•ì¥íŒ)
KEYWORD_CATEGORY_MAP = {
    # ì •ì±…Â·ê·œì œ
    "ì •ì±…": "policy_regulation",
    "ê·œì œ": "policy_regulation",
    "ì •ë¶€": "policy_regulation",
    "ë²•": "policy_regulation",
    "ì„¸ê¸ˆ": "policy_regulation",
    "ê³¼ì„¸": "policy_regulation",
    "ì·¨ë“ì„¸": "policy_regulation",
    "ì–‘ë„ì„¸": "policy_regulation",
    "ì¢…ë¶€ì„¸": "policy_regulation",

    # ì‹œì¥ë™í–¥
    "ì‹œì¥": "market_transaction",
    "ê±°ë˜": "market_transaction",
    "ê°€ê²©": "market_transaction",
    "ë§¤ë§¤": "market_transaction",
    "ë¶€ë™ì‚°": "market_transaction",
    "ì•„íŒŒíŠ¸": "market_transaction",
    "ì£¼íƒ": "market_transaction",
    "ì‹œì„¸": "market_transaction",
    "í•˜ë½": "market_transaction",
    "ìƒìŠ¹": "market_transaction",
    "ì„ëŒ€": "market_transaction",
    "ì „ì„¸": "market_transaction",
    "ì›”ì„¸": "market_transaction",
    "ì§‘ê°’": "market_transaction",

    # ë¶„ì–‘Â·ì…ì£¼
    "ë¶„ì–‘": "development_supply",
    "ì²­ì•½": "development_supply",
    "ì…ì£¼": "development_supply",
    "ê³µê¸‰": "development_supply",
    "ì‹ ì¶•": "development_supply",
    "ëª¨ë¸í•˜ìš°ìŠ¤": "development_supply",

    # ê¸ˆìœµÂ·íˆ¬ì
    "ê¸ˆë¦¬": "finance_investment",
    "ëŒ€ì¶œ": "finance_investment",
    "íˆ¬ì": "finance_investment",
    "ì€í–‰": "finance_investment",
    "ê¸ˆìœµ": "finance_investment",
    "ë‹´ë³´": "finance_investment",
    "ì´ì": "finance_investment",
    "ì£¼ë‹´ëŒ€": "finance_investment",

    # ê°œë°œÂ·ì‚¬ì—…
    "ì¬ê°œë°œ": "construction_development",
    "ì¬ê±´ì¶•": "construction_development",
    "ê°œë°œ": "construction_development",
    "ì •ë¹„": "construction_development",
    "ì‚¬ì—…": "construction_development",
    "ë„ì‹œê°œë°œ": "construction_development",

    # ê±´ì„¤Â·ì‹œê³µ
    "ê±´ì„¤": "construction",
    "ì‹œê³µ": "construction",
    "ì‹œê³µì‚¬": "construction",
    "ê±´ì„¤ì‚¬": "construction",
    "ì°©ê³µ": "construction",

    # ìƒì—…ìš© ë¶€ë™ì‚°
    "ìƒê°€": "commercial_realestate",
    "ì˜¤í”¼ìŠ¤": "commercial_realestate",
    "ë¹Œë”©": "commercial_realestate",
    "ìƒì—…": "commercial_realestate",
    "ì‚¬ë¬´ì‹¤": "commercial_realestate",
    "ì í¬": "commercial_realestate",

    # ê²½ë§¤Â·ê³µë§¤
    "ê²½ë§¤": "auction_public_sale",
    "ê³µë§¤": "auction_public_sale",
    "ìœ ì°°": "auction_public_sale",
}


def classify_article_keyword(title: str, description: str = "") -> list:
    """í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨ ë¶„ë¥˜"""
    text = f"{title} {description}".lower()
    categories = []

    for keyword, category in KEYWORD_CATEGORY_MAP.items():
        if keyword in text:
            if category not in categories:
                categories.append(category)

    # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ (ë¶„ë¥˜ ì•ˆë˜ë©´)
    if not categories:
        categories = ["market_transaction"]

    return categories


def merge_classifications(keyword_categories: list, ai_result: dict) -> dict:
    """
    í‚¤ì›Œë“œ ë¶„ë¥˜ì™€ AI ë¶„ë¥˜ ë³‘í•©

    Args:
        keyword_categories: í‚¤ì›Œë“œ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ë¦¬ìŠ¤íŠ¸
        ai_result: AI ë¶„ë¥˜ ê²°ê³¼ dict
            {
                'categories': list,
                'tags': list,
                'confidence': int,
                'reasoning': str
            }

    Returns:
        {
            'categories': list,  # ìµœì¢… ì¹´í…Œê³ ë¦¬
            'tags': list,        # AI íƒœê·¸
            'confidence': int,   # AI ì‹ ë¢°ë„
            'reasoning': str,    # AI íŒë‹¨ ê·¼ê±°
            'method': str        # ë¶„ë¥˜ ë°©ë²• (keyword, ai, hybrid)
        }
    """
    # AI ì‹ ë¢°ë„ê°€ ì„ê³„ê°’ ì´ìƒì´ë©´ AI ìš°ì„ 
    if ai_result.get('confidence', 0) >= AI_CONFIDENCE_THRESHOLD:
        return {
            'categories': ai_result.get('categories', keyword_categories),
            'tags': ai_result.get('tags', []),
            'confidence': ai_result.get('confidence', 0),
            'reasoning': ai_result.get('reasoning', ''),
            'method': 'ai'
        }

    # AI ì‹ ë¢°ë„ê°€ ë‚®ìœ¼ë©´ í•˜ì´ë¸Œë¦¬ë“œ (í‚¤ì›Œë“œ + AI ì¹´í…Œê³ ë¦¬ í•©ì¹¨)
    else:
        merged_categories = list(set(keyword_categories + ai_result.get('categories', [])))
        return {
            'categories': merged_categories if merged_categories else keyword_categories,
            'tags': ai_result.get('tags', []),
            'confidence': ai_result.get('confidence', 0),
            'reasoning': ai_result.get('reasoning', 'Hybrid: í‚¤ì›Œë“œ + AI ë³‘í•©'),
            'method': 'hybrid'
        }


def get_notion_headers():
    """Notion API í—¤ë”"""
    return {
        "Authorization": f"Bearer {NOTION_API_KEY}",
        "Content-Type": "application/json",
        "Notion-Version": NOTION_API_VERSION
    }


def delete_blocks_from_page(page_id: str, start_index: int = 2):
    """í˜ì´ì§€ì˜ íŠ¹ì • ì¸ë±ìŠ¤ë¶€í„° ë¸”ë¡ ì‚­ì œ"""
    url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    response = requests.get(url, headers=get_notion_headers(), timeout=30)

    if response.status_code != 200:
        return False

    blocks = response.json().get("results", [])
    blocks_to_delete = blocks[start_index:]

    for block in blocks_to_delete:
        delete_url = f"https://api.notion.com/v1/blocks/{block['id']}"
        requests.delete(delete_url, headers=get_notion_headers(), timeout=30)

    return True


def append_blocks_to_page(page_id: str, blocks: list):
    """í˜ì´ì§€ì— ë¸”ë¡ ì¶”ê°€"""
    url = f"https://api.notion.com/v1/blocks/{page_id}/children"
    response = requests.patch(
        url,
        headers=get_notion_headers(),
        json={"children": blocks},
        timeout=30
    )
    return response.status_code == 200


def create_empty_block():
    """ë¹ˆ ë¸”ë¡ ìƒì„±"""
    return {
        "object": "block",
        "type": "paragraph",
        "paragraph": {"rich_text": [{"type": "text", "text": {"content": ""}}]}
    }


def create_footer_blocks(logo_url: str = None):
    """í‘¸í„° ë¸”ë¡ ìƒì„±"""
    blocks = []

    # 3ê°œì˜ ë¹ˆ ì¤„
    for _ in range(3):
        blocks.append(create_empty_block())

    # ë¡œê³  ì´ë¯¸ì§€ (ìˆìœ¼ë©´)
    if logo_url:
        blocks.append({
            "object": "block",
            "type": "image",
            "image": {
                "type": "external",
                "external": {"url": logo_url}
            }
        })

    # íšŒì‚¬ ë¸Œëœë“œ
    blocks.append({
        "object": "block",
        "type": "paragraph",
        "paragraph": {
            "rich_text": [{
                "type": "text",
                "text": {"content": "ë¶€ë™ì‚° ë¹„ì¦ˆë‹ˆìŠ¤ ì „ë¬¸ê°€ë¥¼ ìœ„í•œ\nğŸŸ¦ AIDE INSIGHT | ì—ì´ë“œ ì¸ì‚¬ì´íŠ¸"},
                "annotations": {"bold": True}
            }]
        }
    })

    # íšŒì‚¬ ì •ë³´
    blocks.append({
        "object": "block",
        "type": "paragraph",
        "paragraph": {
            "rich_text": [{
                "type": "text",
                "text": {"content": "(ì£¼)ì—ì´ë“œíŒŒíŠ¸ë„ˆìŠ¤ | ëŒ€í‘œì´ì‚¬: ì†¡ì¸ê·¼ | ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸: 345-81-02007\nì„œìš¸íŠ¹ë³„ì‹œ ì„œì´ˆêµ¬ ê°•ë‚¨ëŒ€ë¡œ97ê¸¸ 26, 4ì¸µ\nÂ© 2025 AIDE Partners Co., Ltd. All rights reserved"}
            }]
        }
    })

    return blocks


def create_article_blocks(date_str: str, category_name: str, articles: list):
    """ê¸°ì‚¬ ë¸”ë¡ ìƒì„±"""
    blocks = []

    # í—¤ë”
    dt = datetime.strptime(date_str, "%Y-%m-%d")
    heading = f"{dt.year}ë…„ {dt.month}ì›” {dt.day}ì¼, {category_name} ì†Œì‹ì…ë‹ˆë‹¤"

    blocks.append({
        "object": "block",
        "type": "paragraph",
        "paragraph": {
            "rich_text": [{
                "type": "text",
                "text": {"content": heading},
                "annotations": {"bold": True}
            }]
        }
    })

    # êµ¬ë¶„ì„ 
    blocks.append({
        "object": "block",
        "type": "divider",
        "divider": {}
    })

    # ê¸°ì‚¬ ëª©ë¡
    for article in articles:
        # ê¸°ì‚¬ì œëª©[1ê±´] ğŸ”— í˜•ì‹
        rich_text = [
            {"type": "text", "text": {"content": f"{article['title']}[{article.get('cluster_size', 1)}ê±´] "}},
            {"type": "text", "text": {"content": "ğŸ”—", "link": {"url": article['url']}}}
        ]

        blocks.append({
            "object": "block",
            "type": "paragraph",
            "paragraph": {"rich_text": rich_text}
        })

    # í‘¸í„° ì¶”ê°€
    footer_blocks = create_footer_blocks(logo_url="https://www.aidepartners.com/images/logo.png")
    blocks.extend(footer_blocks)

    return blocks


def main():
    """ë©”ì¸ í”„ë¡œì„¸ìŠ¤"""
    print("=" * 80)
    print("Hybrid Classify (Keyword + AI) & Upload to Notion")
    print("=" * 80)
    print(f"Date: {date.today().isoformat()}")
    print(f"AI Classification: {'ENABLED' if USE_AI_CLASSIFICATION else 'DISABLED'}")
    print(f"AI Confidence Threshold: {AI_CONFIDENCE_THRESHOLD}%\n")

    # DB ì—°ê²°
    db_url = "sqlite:///" + str(project_root / "aide-data-core" / "aide_dev.db")
    engine = create_engine(db_url)
    Session = sessionmaker(bind=engine)
    db = Session()

    # AI ë¶„ë¥˜ê¸° ì´ˆê¸°í™”
    ai_classifier = None
    if USE_AI_CLASSIFICATION:
        try:
            ai_classifier = AIClassifier()
            print("AI Classifier initialized (GPT-4o-mini)\n")
        except Exception as e:
            print(f"AI Classifier initialization failed: {e}")
            print("Falling back to keyword-only classification\n")

    try:
        # 1. ëª¨ë“  raw ê¸°ì‚¬ ì¡°íšŒ
        articles = db.query(NaverNews).filter(
            NaverNews.status == 'raw'
        ).order_by(NaverNews.date.desc()).all()

        print(f"Found: {len(articles)} articles to process\n")

        if len(articles) == 0:
            print("No raw articles to process. All done!")
            db.close()
            return 0

        # 2. í‚¤ì›Œë“œ ë¶„ë¥˜
        print("Step 1: Keyword-based classification...")
        keyword_classifications = {}
        for article in articles:
            keyword_classifications[article.id] = classify_article_keyword(
                article.title,
                article.description or ""
            )
        print(f"  Classified {len(keyword_classifications)} articles by keywords\n")

        # 3. AI ë¶„ë¥˜ (í™œì„±í™”ëœ ê²½ìš°)
        ai_classifications = {}
        if ai_classifier:
            print("Step 2: AI-based classification (GPT-4o-mini)...")

            # ê¸°ì‚¬ ë°ì´í„° ì¤€ë¹„
            articles_for_ai = [
                {
                    'id': article.id,
                    'title': article.title,
                    'description': article.description or ''
                }
                for article in articles
            ]

            # ë°°ì¹˜ AI ë¶„ë¥˜
            ai_classifications = ai_classifier.classify_batch(articles_for_ai, batch_size=10)
            print(f"  AI classified {len(ai_classifications)} articles\n")
        else:
            print("Step 2: AI classification SKIPPED (disabled or failed)\n")

        # 4. í‚¤ì›Œë“œ + AI ë³‘í•©
        print("Step 3: Merging keyword and AI classifications...")
        articles_by_category = {cat: [] for cat in CATEGORY_PAGES.keys()}
        classification_stats = {'keyword': 0, 'ai': 0, 'hybrid': 0}

        for article in articles:
            keyword_cats = keyword_classifications.get(article.id, ["market_transaction"])
            ai_result = ai_classifications.get(article.id, {})

            # ë³‘í•©
            merged = merge_classifications(keyword_cats, ai_result)
            final_categories = merged['categories']

            # í†µê³„
            classification_stats[merged['method']] += 1

            # ì¹´í…Œê³ ë¦¬ì— ê¸°ì‚¬ ì¶”ê°€
            for cat_code in final_categories:
                if cat_code in articles_by_category:
                    articles_by_category[cat_code].append({
                        'title': article.title,
                        'url': article.url,
                        'id': article.id,
                        'description': article.description or '',
                        'source': article.source or 'ê¸°íƒ€'
                    })

            # DB ì—…ë°ì´íŠ¸
            article.classified_categories = json.dumps(
                [CATEGORY_NAMES.get(c, c) for c in final_categories],
                ensure_ascii=False
            )
            article.status = 'processed'
            article.cluster_representative = True

            # AI ê²°ê³¼ ì €ì¥ (ìˆìœ¼ë©´)
            if merged.get('tags'):
                # íƒœê·¸ëŠ” descriptionì— ì„ì‹œ ì €ì¥ (ì¶”í›„ ë³„ë„ í•„ë“œë¡œ ë¶„ë¦¬ ê°€ëŠ¥)
                article.description = f"{article.description or ''}\n[AI Tags: {', '.join(merged['tags'])}]"

        db.commit()

        print(f"  Classification methods used:")
        print(f"    - Keyword only: {classification_stats['keyword']}")
        print(f"    - AI only: {classification_stats['ai']}")
        print(f"    - Hybrid: {classification_stats['hybrid']}")
        print()

        # 5. Notion ì—…ë¡œë“œ
        print("Step 4: Uploading to Notion...\n")
        today_str = date.today().isoformat()

        for cat_code, cat_articles in articles_by_category.items():
            if not cat_articles:
                continue

            cat_name = CATEGORY_NAMES[cat_code]
            page_id = CATEGORY_PAGES[cat_code]

            # í´ëŸ¬ìŠ¤í„°ë§ ì ìš© (ìœ ì‚¬ ê¸°ì‚¬ ê·¸ë£¹í™”)
            if len(cat_articles) > 1:
                print(f"[{cat_name}] {len(cat_articles)} articles -> clustering...")
                try:
                    representatives, _ = apply_clustering_to_articles(
                        cat_articles,
                        similarity_threshold=0.6
                    )
                    print(f"  Clustered: {len(representatives)} representatives")
                except Exception as e:
                    print(f"  Clustering failed: {e}, using all articles")
                    representatives = cat_articles
                    for art in representatives:
                        art['cluster_size'] = 1
            else:
                print(f"[{cat_name}] {len(cat_articles)} articles (no clustering needed)")
                representatives = cat_articles
                for art in representatives:
                    art['cluster_size'] = 1

            # ê¸°ì¡´ ë¸”ë¡ ì‚­ì œ (3ë²ˆì§¸ë¶€í„°)
            delete_blocks_from_page(page_id, start_index=2)

            # ìƒˆ ë¸”ë¡ ì¶”ê°€ (ìƒìœ„ 20ê°œ ëŒ€í‘œ ê¸°ì‚¬)
            blocks = create_article_blocks(today_str, cat_name, representatives[:20])
            append_blocks_to_page(page_id, blocks)

        print("\n" + "=" * 80)
        print("[SUCCESS] Hybrid classification and upload completed!")
        print("=" * 80)

        db.close()
        return 0

    except Exception as e:
        print(f"\n[ERROR] {e}")
        import traceback
        traceback.print_exc()
        db.close()
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
